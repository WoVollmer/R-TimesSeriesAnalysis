---
title: Climate Data Forecasting -
subtitle: Atmospheric $CO_2$ Concentration / Temperature / Precipitation
author: "Wolfgang Vollmer"
date: '`r Sys.Date()`'
output:
  pdf_document:
    fig_caption: no
    number_sections: yes
    toc: yes
    toc_depth: 3
  html_document: default
urlcolor: blue
papersize: a4
params:
  city: "Mannheim"
  temp_precip: "both" 
  
knit: (
  function(inputFile, encoding) { 
    city <- "Mannheim"
  
    rmarkdown::render( 
      input       = inputFile, 
      output_file = paste(substr(inputFile,1,nchar(inputFile)-4), city, 
                          Sys.Date(), sep = "_")) })  
---


```{r setup, include=FALSE}
################################################################################
## Plot and Analyze                                                           ##
## Yearly/Monthly CO2 or Climate Temperature / Precipitation Data             ##
##                                                                            ##
##                                            Wolfgang Vollmer, January 2026  ##
################################################################################
knitr::opts_chunk$set(eval = TRUE, echo = FALSE, warning = FALSE,      
                      message = FALSE, fig.width = 7, fig.asp = 0.618)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE
)

city <- params$city
temp_precip_selected <- params$temp_precip

eval_stat_diff <- TRUE # execute, plot "stationary difference chunks"
eval_ets <- TRUE       # execute, plot "ETS Forecasting chunks"
eval_arima <- TRUE    # execute, plot "ARIMA Forecasting chunks"
eval_ets_arima <- TRUE  # execute, plot "ETS vs. ARIMA Forecasting chunks"
eval_yearly <- TRUE # yearly data - execute, plot "ARIMA/ETS Forecasting chunks"

eval_backup <- TRUE
eval_test <- FALSE # execute and plot additional "test chunks"

setwd(dirname(rstudioapi::getSourceEditorContext()$path))
```


```{r Add config and data, child = 'Climate_Config.Rmd', eval=TRUE}
```

```{r,  include=FALSE}

# if (length(measure_analysis)  > 1) { 
#   stop(paste(paste(city, collapse = ", "), 
#              "- support of both measures, ", measure, ", is not implemented")) 
# }

key <- c("City", "Measure")   # all data have to have "City" & "Measure" column
# key <- c("Measure") # w/o City reduces "strip" naming w/ facet_wrap/grid

```

```{r get data w interpolated, include=FALSE}

# ETS / ARIMA models does not allow NAs
# 
# always only the the count column is used 
# => if interpolated values exist => they are included in count column
get_data_w_interpolated <- FALSE

if (get_data_w_interpolated) {
  data_monthly <- readRDS(paste0("./Data_rds_Temp_Precip_CO2/", city,
                                 "_data_monthly_w_interpol.rds"))
  data_monthly <- data_monthly %>% 
    dplyr::filter(Measure == measure) 
  data_monthly <- data_monthly %>%
    as_tsibble(index = Year_Month, key = all_of(key))
}

# same as above but already w/ Raw Interpolated NA_replace
# A tsibble: 1,884 x 9 [1M]
# Key:       City, Measure [1]
# Groups:    City, Measure [1]
 #   City  Measure     Year_Month  Year Month count   Raw NA_replace
 #   <chr> <fct>            <mth> <dbl> <fct> <dbl> <dbl> <lgl>     
 # 1 Basel Temperature   1864 Jan  1864 Jan    -5.5  -5.5 NA 

data_yearly <- uts_gen_yearly_seasonal_avg(data_monthly) %>% 
  as_tsibble(index = Year, key = key) %>% 
  select(count = Year_avg) # select w/ renaming: select(count = Year_avg)
# A tsibble: 157 x 8 [1Y]
# Key:       City, Measure [1]
# Groups:    City, Measure [1]
 #   City  Measure      Year Winter_avg Spring_avg Summer_avg Fall_avg  count
 #   <chr> <fct>       <dbl>      <dbl>      <dbl>      <dbl>    <dbl>    <dbl>
 # 1 Basel Temperature  1864     NA           9.1        16.3     8.07     7.7 

measure_nr <- nrow(data_monthly %>% distinct(Measure))
measure <- tibble(data_monthly) %>% distinct(Measure)
measure <- as.character(as_vector(measure))

city <- as_vector(city)
city_measure <- paste(city, measure)

```


```{r settings old from forecast , eval = TRUE, include = FALSE}


##### dafault settings for Temperature/Precipitation to be adjusted

test_data_year_range <- 10
forecast_test_data_range <- paste(test_data_year_range, "years", collapse = ", ")
training_data_year_start <- last_year - 6*test_data_year_range 
training_data_year_end   <- last_year - test_data_year_range
# start always with > training_data_year_start 
# for last_year = 2025:
# data_test  from 2016 - 2025
# data_train from 1966 - 2015

if (training_data_year_start < first_year) { 
  stop(paste("First year of data", first_year, 
              "after start of training data range, test data range of",
              test_data_year_range, "years to long !")) 
}

```


# Forecasting of `r title_rmd`

## Stationarity and differencing

Stationary time series is one whose properties do not depend on the time at which 
the series is observed. Thus, time series with trends, or with seasonality, are 
not stationary — the trend and seasonality will affect the value of the time series 
at different times. On the other hand, a white noise series is stationary — 
it does not matter when you observe it, it should look much the same at any point in time.

Stationary time series will have no predictable patterns in the long-term. 
Time plots will show the series to be roughly horizontal 
(although some cyclic behaviour is possible), with constant variance.

If ${y_t}$ is a *stationary* time series, then for all $s$, the distribution of  
$(y_t, ..., y_{t+s})$ does not depend on $t$.

If Time Series data with seasonality are non-stationary

* => first take a seasonal difference
* if seasonally differenced data appear are still non-stationary 
* => take an additional first seasonal difference

The model fit residuals have to be stationary. For good forecasting this has 
to be verified with residual diagnostics.

Essential:

* Residuals are uncorrelated
* The residuals have zero mean

Useful (but not necessary):

* The residuals have constant variance.
* The residuals are normally distributed.

```{r gen plot differencing, eval = eval_stat_diff, fig.width = 7, fig.height = 8}
data_diff <- data_monthly %>% 
  mutate(diff_sd1_d0 = difference(count, 12),
         # diff_sd0_d1 = difference(count, 1),
         diff_sd1_d1 = (difference(count, 12) %>% difference(1)))
         # diff_sd1_d2 = 
         #   (difference(count, 12) %>% difference(1)  %>% difference(1)))
  # diff_sd1_d2 = difference(difference(difference(count, 12), 1), 1)
  # are identical
       
data_diff %>%
  filter(year(Year_Month) >= 1990) %>%
  pivot_longer(cols = c(count, starts_with("diff_")),
  names_to = "differences",
  values_to = "value") %>%
  ggplot(aes(x = Year_Month, y = value)) +
  geom_line() +
  facet_grid(vars(Measure, differences), scales = "free_y") +
  labs(x = "Year", y = NULL,
       title = "Seasonal difference and further differences to obtain stationary")

```
\newpage


### Unitroot KPSS Test - fix number of seasonal differences/differences required

* For **ARIMA model** use Unitroot KPSS Test to fix number of differences
    + unitroot_nsdiffs() to determine *D* (the number of seasonal differences to use)
    + unitroot_ndiffs() to determine *d* (the number of ordinary differences to use)
    + The selection of the other model parameters (p,q,P and Q) are all determined by minimizing the AICc

* kpss test of stationary of the differentiated data 
(with seasonal and ordinary differences) used in the **ARIMA model**
    + stationary times series: the distribution of $(y_t, ..., y_{t-s})$ does not depend on $t$.  
    + *Null Hypothesis* $H_0$: stationary is given in the time series: data are stationary and non seasonal  
        + for $p<\alpha = 0.05$ : reject $H_0$
        + for $p>>\alpha = 0.05$ : conclude: differentiated data are stationary and non seasonal

* kpss test of stationary w/ unitroot_nsdiffs & unitroot_ndiff provides 
    + minimum number of seasonal & ordinariel differences required for a stationary series
    + first fix required seasonal differences and then apply ndiffs to the seasonally differenced data
    + returns 1 => for stationarity one seasonal difference rsp. difference is required

```{r Unitroot KPSS test, eval = eval_stat_diff}


cat("  ndiffs gives the number of differences required and \n",
    "nsdiffs gives the number of seasonal differences required \n",
            "- to make a series stationary (test is based on the KPSS test\n\n")
# returns 1 => one difference/seasonal difference is required for stationarity
# returns 0 =>  no further difference/seasonal difference is required for stationarity
cat("unitroot_kpss test to define seasonal (nsdiffs) and ordinary (ndiffs) differences\n")
data_monthly %>%  
  features(count, list(unitroot_kpss, unitroot_nsdiffs, unitroot_ndiffs))

cat("unitroot_kpss test on (difference(count, 12) + difference())\n")
data_monthly %>%
  features((difference(count, 12) %>% difference(1)), unitroot_kpss, lag = 10)

```

### Ljung-Box Test - independence/white noise of the time series

The Ljung-Box Test becomes important when checking independence/white noise of 
the forecasts residuals of the fitted ETS rsp. ARIMA models. There we have to 
check whether the forecast errors are normally distributed with mean zero

* augment(fit) |> features(.innov, ljung_box, lag=x, dof=y) (Ch. 5.4 Residaul diagnostics)
    + portmanteau test suggesting that the residuals are white noise
    + *Null Hypothesis* $H_0$: independence/white noise for residuals, i.e. each 
    autocorrelation in the time series residuals of the model for lag l is close to zero.  
        + for $p<\alpha = 0.05$ : reject H_0
        + for $p>>\alpha = 0.05$ : conclude: the residuals are not distinguishable from a white noise series
    + lag = 2*m (period of season, e.g. m=12 for monthly season) | no season: lag=10
    + dof = p + q + P + Q (for ARIMA models only, degree of freedom)

Time series with trend and/or seasonality is not stationary. Tests are to be taken on the residuals of the fitted models.

```{r Ljung–Box test, eval = eval_stat_diff}
# Ljung-Box statistic - testing if a time series is white noise
# null hypothesis of independence/white noise in a given time series
#                 => h0 to be rejected for p < alpha
# p-value < 0.05 => null hypothesis to be rejected 
# => data in the given time series are dependent
#    => differenced data are needed to get stationary

cat("Ljung–Box test with (count), w/o differences\n")
data_monthly %>%
  features(count, ljung_box, lag = 10)

cat("Ljung–Box test on (difference(count, 12))\n")
data_monthly %>%
  features(difference(count, 12), ljung_box, lag = 10)

cat("Ljung–Box test on (difference(count, 12) + difference())\n")
data_monthly %>%
  features((difference(count, 12) %>% difference(1)), ljung_box, lag = 10)

```


### ACF (Autocorrelation Function) Plots of Differences


```{r ACF Difference Plots, eval = eval_stat_diff}
plot_1 <- data_monthly %>% ACF(count) %>% autoplot() +
  ggtitle("ACF(count)")
plot_2 <- data_monthly %>% ACF(difference(count, 1)) %>% autoplot() +
  ggtitle("ACF(difference(count, 1)")
plot_3 <- data_monthly %>% ACF(difference(count, 12)) %>% autoplot() +
  ggtitle("ACF(difference(count, 12))")
plot_4 <- data_monthly %>% ACF(difference(count, 12) %>% difference(1)) %>% autoplot() +
  ggtitle("ACF(difference(12) + difference())")
gridExtra::grid.arrange(plot_1, plot_2, plot_3, plot_4)

```

### Time Series, ACF and PACF (Partial) Plots of Differences - for ARIMA p, q check

```{r Triplet Time Series ACF PACF Difference Plots, eval = eval_stat_diff}

data_monthly <- data_monthly %>% as_tsibble(index = Year_Month, key = key)

# data with seasonality are non-stationary
# => first take a seasonal difference
for (i in unique(key_data(data_monthly)[[1]])) {     # City
  for (j in unique(key_data(data_monthly)[[2]])) {   # Measure
    data <- data_monthly %>% filter(City == i, Measure == j)
    
    # sum of residuals w/o difference
    print(
      as_tibble(data) %>%
        mutate(diff_count = count) %>% 
        summarise(Sum = sum(diff_count, na.rm = TRUE),
                  Mean = mean(diff_count, na.rm = TRUE)))
    print(
      data %>% 
        gg_tsdisplay(count, plot_type='partial') +
        ggtitle("Time Series, ACF & PACF for (count) ",
                paste(i, "-", j))
    )
    
    # sum of residuals with difference(count, 12)
    print(
      as_tibble(data) %>%
        mutate(diff_count = difference(count, 12)) %>% 
        summarise(Sum = sum(diff_count, na.rm = TRUE),
                  Mean = mean(diff_count, na.rm = TRUE)))
    print(
      data %>% 
        gg_tsdisplay(difference(count, 12), plot_type='partial') +
        ggtitle("Time Series, ACF & PACF for (difference(count, 12))",
                paste(i, "-", j))
    )
    
    # sum of residuals with difference(count, 12) %>% difference(1)
    print(
      as_tibble(data) %>%
        mutate(diff_count = difference(count, 12) %>% difference(1)) %>% 
        summarise(Sum = sum(diff_count, na.rm = TRUE),
                  Mean = mean(diff_count, na.rm = TRUE)))
    # if seasonally difference data appear to be non-stationary
    # => take an additional first seasonal difference
    print(
      data %>% 
        gg_tsdisplay(difference(count, 12) %>% difference(1), plot_type='partial') +
        ggtitle("Time Series, ACF & PACF for (difference(count, 12) + difference(1))",
                paste(i, "-", j))
    )
  }
}            
```
\newpage

# ExponenTial Smoothing (ETS) Forecasting Models

Forecasts produced using exponential smoothing methods are weighted averages of 
past observations, with the weights decaying exponentially as the observations 
get older. 

The parameters are estimated by maximising the “likelihood”. The likelihood is the probability of the data arising from the specified model. 
AIC, AICc and BIC can be used here to determine which of the ETS models is most appropriate for a given time series (see output glance(fit_ets)).

The model selection is based on recognising key components of the 
time series (trend and seasonal) and the way in which these enter the 
smoothing method (e.g., in an additive, damped or multiplicative manner).

* Mauna Loa $CO_2$ data best Models: ETS(M,A,A) & ETS(A,A,A)
* Basel Temperature data best Models: ETS(A,N,A), ETS(A,A,A), ETS(A,Ad,A) (close togehter). Best Forecast accuracy is with ETS(A,A,A), ETS(A,Ad,A). 
* Basel Precipitation data best Models: ETS(A,N,A),  ETS(A,Ad,A), ETS(A,A,A) (close togehter). Best Forecast accuracy is with ETS(A,A,A), ETS(A,Ad,A), ETS(A,N,A),

Trend term "N" for Basel Temperature/Precipitation correspondends to a "pure" exponential smooothing which results in a slope $\beta = 0$.
This results in a forecast predicting a constant level. This does not fit to the
result of the STL decomposition. Therefore best model choice is **ETS(A,A,A)**.

**Method Selection**

*Error term:* either additive ("A") or multiplicative ("M"). 

Both methods provide identical point forecasts, but 
different prediction intervals and different likelihoods.
AIC & BIC are able to select between the error types because they are based on likelihood.

Nevertheless, difference is for 

* Mauna Loa $CO_2$ not relevant and AIC/AICc/BIC values are only a little bit 
smaller for multiplicative errors. The prediction intervall plots are fully overlapping.
* Basel Temperature AIC/AICc/BIC of additive error types are much better than 
the multiplicative ones.
* Basel Precipitation AIC/AICc/BIC of additive error types are much better than the multiplicative ones.

Note: For Basel Temperature and Precipitation Forecast plots the models
ETS_MAdA, ETS_MMA, ETS_MMA, ETS_MNA are to be taken out since forecasts with
multiplicative errors are exploding (forecast > 3 years impossible !!)

Therefore finally  **Error term = "A"** is chosen in general. 


*Trend term:* either none ("N"), additive ("A"), multiplicative ("M") or 
damped variants ("Ad", "Md").

Note: Mauna Loa $CO_2$ model ETS(A,Ad,A) fit plot shows to strong damping.
For Basel Temperature model ETS(A,N,A) and ETS(A,Ad,A) are providing more or less
the same forecast. This means that forecast remains on constant level since Trend "N" means "pure" exponentiell smoothing without trend (see above).
 
Therefore finally  **Trend term = "A"** is chosen in general. 

*Seasonal term:* either none ("N"), additive ("A") or multiplicative ("M").

For CO2 and Temperature Data we have a clear seasonal pattern and seasonal term adds
always a (more or less) fix amount on level and trend component. Therefore "A" 
additve term is chosen. For Precipitation the seasonal patttern is only slight.
Indead, a multiplicative seasonal term results in "exploding" forecasts.

Since monthly data are strongly seasonal **seasonal term  "A"** is chosen.

\newpage

## ETS Models and their componentes

**ETS model with automatically selected $ETS(A|M,N|A|M,N|A|M)$**


```{r Forecasting with default ETS and ARIMA model, eval = eval_ets}
print("model(ETS(count)) => provides default / best automatically chosen model")
# filtering e.g. < 2010 allows generating of test data 2010-2019
fit_def <- filter(data_monthly, year(Year_Month) > training_data_year_start) %>%
  model(
    # ARIMA = ARIMA(count),
    ETS = ETS(count)
    )
fit_def

fit_ets_def <- fit_def %>% select(City, Measure, ETS)
# fit_arima_def <- fit_def %>% select(City, Measure, ARIMA)

# report( fit_ets_def)
for(i in 1:measure_nr) {
  print(city_measure[i])
  report(fit_ets_def %>% filter(Measure == measure[i]))
  # report(fit_arima_def %>% filter(Measure == measure[i]))
}

glance(fit_def) %>% select(-sigma2, -log_lik, -AMSE)

```


**Fit of different pre-defined $ETS(A|M,N|A|M,N|A|M)$ models**

```{r Forecasting with ETS models, eval = eval_ets}

# cat('model(ETS(count ~ error("A"))) => provides best automatically chosen model \n',
#     'w/ pre-conditon error = "A"') 
#  fit_ets_def<- filter(data_monthly, year(Year_Month) > training_data_year_start) %>%
#   model(ETS(count ~ error("A")))
# glance( fit_ets_def)
# report( fit_ets_def)

# fit$"ETS(count)"
# model_ets <- fit[[3]] #  fit$"ETS(count)"
# model_ets <- as.character(format(model_ets))

# fit_ets_allwith different models and provide plot with all
# select by plot and with lowest AIC/AICc/BIC values provided by glance(fit_ets)
# model fit period of time:
#        > training_data_year_start - until last data = last_year (1970-2019)
fit_ets_all <- 
  filter(data_monthly, year(Year_Month) > training_data_year_start) %>%
  model(ETS_ANA = ETS(count ~ error("A") + trend("N") + season("A")),
        ETS_MNA = ETS(count ~ error("M") + trend("N") + season("A")), 
        ETS_AAA = ETS(count ~ error("A") + trend("A") + season("A")),
        ETS_MAA = ETS(count ~ error("M") + trend("A") + season("A")),
        ETS_AAdA = ETS(count ~ error("A") + trend("Ad") + season("A")),
        ETS_MAdA = ETS(count ~ error("M") + trend("Ad") + season("A")), 
        ETS_AMA = ETS(count ~ error("A") + trend("M") + season("A")),
        ETS_MMA = ETS(count ~ error("M") + trend("M") + season("A")))
# for multilicative errors (identical point forecasts with additive errors)
# prediction intervalls are exploding for Temperature and Precipitation !
# no fit_ets_allforecast plot usefull !!


# model_ets <- fit$ETS_AAA
# model_ets <- as.character(format(model_ets))

# tidy(fit_ets)    # summarizes a model's statistical findings such as coefficients
# augment(fit_ets) # adds columns to the original data such as predictions, residuals 
             #                     and cluster assignments



```

**Model Selection by Information Criterion - lowest AIC, AICc, BIC**

Best model fit with

* CV, AIC, AICc and BIC with the lowest values
* Adjusted $R^2$ the model with the highest value.


```{r ETS model selection, eval = eval_ets}
# cat("Model Selection by Information Criterion - lowest AIC, AICc, BIC\n")
glance(fit_ets_all) %>% arrange(AICc, AIC, BIC) %>% select(-sigma2, -log_lik) 
                       
# glance(fit_ets_all) %>% summarise(min(AIC), min(AICc), min(BIC))
# report(fit_ets_all) # only working for single models !

# components(fit_ets_all)

# plot of ETS components
for(i in 1:measure_nr) {
  plot <- components(fit_ets_all) %>% filter(Measure == measure[i]) %>% 
  filter(.model == "ETS_ANA" | .model == "ETS_MNA" | .model == "ETS_AAA" | .model == "ETS_MAA") %>% 
  autoplot() +
  ggtitle(paste(measure[i], "ETS Model - Components"))
  print(plot)
}



```


### Residual Accuracy with one-step-ahead fitted residuals - check RMSE, MAE

Residual accuracy can be computed directly from models as the one-step-ahead fitted residuals are available. Select forecast models that minimises for lowest

* MAE (Mean absolute error, will lead to forecasts of the median) and 
* RMSE (Root mean squared error, lead to forecasts of the mean)

```{r Residual accuracy ETS, eval = eval_ets}

# Residual accuracy
# can be computed directly from models as the one-step-ahead fitted residuals
# are available  
# check forecast method that minimises for lowest 
# MAE (Mean absolute error, will lead to forecasts of the median) and 
# RMSE (Root mean squared error, lead to forecasts of the mean)
fit_ets_all %>% accuracy() %>% arrange(RMSE, MAE) %>% select(1:MAE)

```

### Ljung-Box Test - independence/white noise of the forecasts residuals

```{r ETS model ljung_box test residuals, eval = eval_ets}

# ljung_box Test: dof - Degrees of freedom of the fitted model 
#                           (useful if x is a series of residuals)
cat("Null Hypothesis of independence/white noise for residuals - for p < 0.05: reject H_0\n")
augment(fit_ets_all) %>%
  features(.resid, ljung_box, lag = 24, dof = 3) %>% arrange(desc(lb_pvalue))

```


### ETS Models - components of ETS(A,N,A), ETS(A,A,A), ETS(A,Ad,A), models

```{r ETS components of reduced models, eval = eval_ets}

# for Forecast Accuracy with Training/Test Data
# select fit models with lowest AICc, lowest RMSE/MAE and white noise of 
# forecast residuals
fit_ets_all <- dplyr::select(fit_ets_all, City, Measure, ETS_ANA, ETS_AAA, ETS_AAdA)

# model_ets <- fit_ets_all$ETS_AAA
# model_ets <- as.character(format(model_ets))
# paste(names(fit_ets_all),  collapse= "; ")
# paste(unique(fc_ets_all$.model), collapse= "; ")

# components(fit_ets_all)

# plot of ETS components
components(fit_ets_all) %>%
  autoplot() +
  ggtitle("Model - Components") # +
   # guides(colour=guide_legend(title=paste(city, "\n", measure_analysis, "\n",
   #                                        "Model")))

```


### Forecast Accuracy with Training/Test Data

```{r ETS forecasts accuracy, eval = eval_ets}
# forecast_test_data_range
# training_data_year_start 
# training_data_year_end
# 
# training data 1970-2009, total data: 1970 - 2019, => test data: 2010-2019
# model fit period of time:
#           training_data_year_start - until last data = last_year (1970-2019) 
fit_ets_train <- filter(data_monthly, 
                        year(Year_Month) > training_data_year_start  &
                          year(Year_Month) <= training_data_year_end) %>%
  model(ETS_ANN = ETS(count ~ error("A") + trend("N") + season("N")),
        # w/o season component - average of ETS_ANA
        ETS_ANA = ETS(count ~ error("A") + trend("N") + season("A")),
        ETS_AAA = ETS(count ~ error("A") + trend("A") + season("A")),
        ETS_MAA = ETS(count ~ error("M") + trend("A") + season("A")),
        ETS_AAdA = ETS(count ~ error("A") + trend("Ad") + season("A")))
# forecasts accuracy
# for evaluating accuracy on forecasts to be provided:
# - a complete dataset that includes the future data and 
# - data used to train the model.
fc_ets_train <- fit_ets_train %>% fabletools::forecast(h = forecast_test_data_range) # long running

# forecasts accuracy
# for evaluating accuracy on forecasts to be provided:
# - a complete dataset that includes the future data and 
# - data used to train the model.

# fc_ets_train %>% accuracy(data_monthly) need trainings data
accuracy(fc_ets_train, 
         filter(data_monthly, year(Year_Month) > training_data_year_start)) %>% 
  arrange(RMSE, MAE) %>% select(1:MAE)

# with further data filtering only xlims are adapted, no forecast impact
# level = prediction interval in % or NULL
fc_ets_train %>%
  autoplot(filter(data_monthly, year(Year_Month) >= 2000), level = NULL) +
  labs(x = "Year", y = y_label) +
  ggtitle("Accuracy of Monthly Forecasts", 
          paste(city, "-", measure,
                "note: ET(Axy)/ETS(Mxy) are in general overlapping")) +
  guides(colour=guide_legend(title="Forecast"))



```


```{r select ETS model and provide var model_ets, eval = eval_ets}
# fit$ets
# model_ets <- fit$ets # fit[[3]]
# model_ets <- as.character(format(fit$ets))
selected_ets_model <- "ETS_AAA"  # to be independent from selected model name
fit_ets <- dplyr::select(fit_ets_all, City, Measure, selected_ets_model) %>% 
  rename(ets = selected_ets_model)
model_ets <- as.character(format(fit_ets$ets))

```

\newpage

## Forecasting with selected ETS model `r model_ets`

### Forecast Plot of selected ETS model

```{r Plot selected ETS model forecast, eval = eval_ets}

cat("Provide model coefficients by report(fit_model)")
report(fit_ets)

fit_ets %>% 
  components() %>% 
  autoplot() +
  ggtitle("Model - Components", as.character(format(fit_ets$ets)))

# calculate forecasts beyond last_year
# to take forecast_test_data_range required for training forecast only,
#       beyond forecast could be different, longer periods of time need more run time

# calculate forecasts
fc_ets <- fit_ets %>% fabletools::forecast(h = "30 years") # long running

# Plot ETS model forecasts and choose appropriate range of data before forecast
#  autoplot: data + forecast AAA & forecast MAA w/ or w/o signif. level (def=80&95%)
#   /prediction interval;  level = NULL /= 95 => w/o signif. level / w/ 95% 
data <- filter(data_monthly, year(Year_Month) >= 2010) 
fc_ets %>%
  autoplot(data,  alpha = 0.5) +
  labs(x = "Year", y = y_label, col = "Forecast",
        title = paste("Forecasts by ETS model", model_ets),
        subtitle = "w/ Prediction Interval")


# print(getAnywhere(report.ETS))  # method.class => provides source code
# report(filter(fit_ets, Temp_Precip == "Temperature" & City == "Basel"))
# report(filter(fit_ets, Temp_Precip == "Precipitation" & City == "Basel"))

```

### Residual Stationarity

Required checks to be ready for forecasting:

* ACF Forecast Residual: all spikes are within the significance limits, so the residuals appear to be white noise
* The Ljung-Box test also shows that the residuals have no remaining autocorrelations
* Forecast Residuals are more or less normally distributed with roughly centred on zero

```{r Plot ETS ACF Residuals, eval = eval_ets}
# residuals(fit_ets)
# residuals(fit_ets, type = "response")

# a correlogram of the forecast errors 
# acf(rainseriesforecasts2$residuals, lag.max=20)
#  filter for single model not required
plot_1 <- filter(residuals(fit_ets), .model == "ets") %>%  
  ACF(.resid, lag.max = 36) %>% autoplot() +
  labs(title = "ACF Correlogram - Forecast Residuals",  subtitle = model_ets) +
    facet_wrap(vars(!!!key(data_monthly)), ncol = 1,  scales = "free_y",
             strip.position = "left")
plot_2 <- filter(residuals(fit_ets), .model == "ets") %>%
  PACF(.resid, lag.max = 36) %>% autoplot() +
  labs(title = "PACF - Forecast Residuals", subtitle ="ets") +
    facet_wrap(vars(!!!key(data_monthly)), ncol = 1,  scales = "free_y",
             strip.position = "left")
gridExtra::grid.arrange(plot_1, plot_2)
```


```{r ETS forecast residuals, eval = eval_ets}
## !! for data with more than one time series
## => filter a single time series to use gg_lag(), gg_tsdisplay(), gg_tsresiduals

## arttention: for Cottbus Plot with Spectrum throws an error =>error = TRUE !!
## - up to know only for Cottbus Precipitation (w/ Temperature running) 
## - Fehler in .$spec[, 1] : falsche Anzahl von Dimensionen

year_filter <- 2000

if (n_keys(data_monthly) == 1 | length(key(data_monthly)) == 2) {    
  for (i in unique(key_data(data_monthly)[[1]])) {
    for (j in unique(key_data(data_monthly)[[2]])) {
      plot_ts <- fit_ets %>%  filter(City == i & Measure == j) %>%  
        gg_tsresiduals() + 
        labs( x = "Year", y = y_label_measure[j], 
              title = " Forecast Residuals w/ ACF Correlogram and Histogram", 
       subtitle = paste("Model:", model_ets))
      print(plot_ts)
      
    }
  } 
} else {
  abort(paste("nothing implemented for n_keys/key_data/key(data_monthly) =", 
              n_keys(data_monthly), key_data(data_monthly), (key(data_monthly))))
}
```

### Ljung-Box Test and Histogram of forecast residuals with overlaid normal curve


```{r Ljung-Box Test ETS, eval = eval_ets_arima}

cat("Null Hypothesis of independence/white noise for residuals - for p < 0.05: reject H_0\n")
augment(fit_ets) %>% filter(year(Year_Month) >= year_filter) %>% 
  features(.resid, ljung_box, lag = 24)

```

```{r Ljung-Box Tests ETS residuals, eval = eval_ets}

# check for independence/white noise of residuals => ljung_box test

# check: is the forecast errors are more or less normally distributed 
# with roughly centered on zero (mean zero)?
# => plot histogram of forecast errors, with an overlaid normal curve with 
#    same mean zero and standard deviation
#    
#  => overlaid normal curve not working correct with facet_wrap()

# if (n_keys(data) == 2 | length(key(data)) == 3) { # one key added by .model
for (i in unique(key_data(data)[[1]])) {     # City
  for (j in unique(key_data(data)[[2]])) {   # Measure
    
    data_filtered <- filter(augment(fit_ets), year(Year_Month) >= year_filter & 
                              City == i, Measure == j)
    plot_histo <- ggts_histo_forecast_resid(data_filtered) +
      labs(title = paste("Histogram of Forecast Residuals -", i, j),  
           subtitle = model_ets)
    print(plot_histo)
  }
}
# } else {
#   abort(paste("nothing implemented for n_keys/key_data/key(data_monthly) =", 
#               n_keys(data_monthly), key_data(data_monthly), (key(data_monthly))))
# }

```

\newpage

# ARIMA Forecasting Models - AutoRegressive-Integrated Moving Average

Exponential smoothing and ARIMA (AutoRegressive-Integrated Moving Average )models
are the two most widely used approaches to time series forecasting, and provide
complementary approaches to the problem.

While exponential smoothing models are based on a description of the trend and 
seasonality in the data, ARIMA models aim to describe the autocorrelations in the data.

## Seasonal ARIMA models

Non-seasonal ARIMA models are generally denoted ARIMA(p,d,q) where parameters 
p, d, and q are non-negative integers, 
* p is the order (number of time lags) of the autoregressive model
* d is the degree of differencing (number of times the data have had past values subtracted)
* q is the order of the moving-average model of past forecast errors .

The value of d has an effect on the prediction intervals — the higher the value 
of d, the more rapidly the prediction intervals increase in size. For d=0, 
the point forecasts are equal to the mean of the data and the long-term 
forecast standard deviation will go to the standard deviation of the 
historical data, so the prediction intervals will all be essentially the same.
 
Seasonal ARIMA models are usually denoted ARIMA(p,d,q)(P,D,Q)m, where m refers 
to the number of periods in each season, and the uppercase P,D,Q refer to the autoregressive, differencing, and moving average terms for the seasonal part of 
the ARIMA model.

**$ARIMA(pdq)(PDQ)$ model with automatically selected $(pdq)(PDQ)$ values**

```{r Seasonal ARIMA automatically, approx, eval = FALSE}
# ```{r Seasonal ARIMA automatically, approx, eval = eval_arima}

# Seasonal ARIMA - find an appropriate ARIMA model with long running approach
# only for first manual check to include in the model list, needs long time

#  automatically select pdq() and PDQ()
fit_arima_def <- data_monthly %>% 
  model(default = ARIMA(count)) # , stepwise = FALSE, approximation = FALSE))
  # model(arima = ARIMA(count ~ pdq(, 0, ) + PDQ( , 1, )))
  # pre-defined: d=0, D=1
report(fit_arima_def)
glance(fit_arima_def) %>% select(City:BIC)

# error if  length(measure) > 1 !!
fit_arima_def %>% gg_tsresiduals(lag_max = 36) +
  ggtitle("Model w/ automatically selected pdq() and PDQ()",
          as.character(format(fit_arima_def$default)))


for(i in 1:measure_nr) {
  print(city_measure[i])
  fit_ets_sel <- 
    fit_ets_def %>% filter(Measure == measure[i]) %>% slice(1) %>% select(3) %>% pull()
  fit_arima_sel<- 
    fit_arima%>% filter(Measure == measure[i]) %>% slice(1) %>% select(3) %>% pull()
    
  plot_ets <- fit_ets_def %>% filter(Measure == measure[i]) %>% 
    ggtime::gg_tsresiduals(lag_max = 24) + 
    # lag = 2*m (lenght of seasonal period), w/o seasonal: use lag = 10
    labs(title = paste(measure[i], "Residuals for fit model ", fit_ets_sel))
  print(plot_ets)
  
  plot_arima <- fit_arima_def %>% filter(Measure == measure[i]) %>% 
    ggtime::gg_tsresiduals(lag_max = 24) + 
    # lag = 2*m (lenght of seasonal period), w/o seasonal: use lag = 10
    labs(title = paste(measure[i], "Residuals for fit model ", fit_arima_sel))
  print(plot_arima)
}

```


```{r Seasonal ARIMA for Data_Monthly default, eval = eval_arima}
# Seasonal ARIMA - find an appropriate ARIMA model


#  automatically select pdq() and PDQ()
# fit_arima_all<- data_monthly %>% model(arima = ARIMA(count,
#                               stepwise = FALSE, approximation = FALSE))
# setting stepwise=FALSE and approximation=FALSE 
#    => R work extra hard to find a good model
#
# for Muna Loa provides: ARIMA(1,1,1)(0,1,1)[12]  w/ AICc: 402.
# w/ stepwise & approx:  ARIMA(0,1,2)(1,1,2)[12]  w/ AICc: 402.
# 
# for Basel Temperature: ARIMA(3,0,0)(1,1,1)[12]  w/ AICc: 2814.
# w/ stepwise & approx:  ARIMA(1,0,2)(2,1,1)[12]  w/ AICc: 2814.
#
# for Basel Precipitation: ARIMA(1,0,0)(2,0,0)[12] w/ mean w/ AICc: NA
# w/ stepwise & approx:    ARIMA(0,0,1)(0,0,2)[12] w/ mean w/ AICc: 71xy

```


**Fit of different pre-defined $ARIMA(pdq)(PDQ)$ models**

```{r Seasonal ARIMA for Data_Monthly, eval = eval_arima}

# model fit period of time:
#         > training_data_year_start - until last data = last_year (1970-2019)
fit_arima_all <- 
  filter(data_monthly, year(Year_Month) > training_data_year_start) %>%
  model(
# default_long = ARIMA(count),
    arima_012_112 = ARIMA(count ~ pdq(0,1,2) + PDQ(1,1,2)), # CO2 opt short run
    arima_102_211 = ARIMA(count ~ pdq(1,0,2) + PDQ(2,1,1)), # Temperature opt short run
    arima_001_002 = ARIMA(count ~ pdq(0,0,1) + PDQ(0,0,2)), # Precip opt short run
# default_long = ARIMA(count, stepwise = FALSE, approx = FALSE),
    arima_111_011 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,1)), 
      # CO2 opt long run & 1.best CO2 & 1.best Temperature  & 2.best Precip
    arima_100_200 = ARIMA(count ~ pdq(1,0,2) + PDQ(2,1,1)), # Precip opt long run
    arima_300_111 = ARIMA(count ~ pdq(3,0,0) + PDQ(1,1,1)), # Temperature opt long run
    # default with D=d=1    
    arima_x1y_m1n = ARIMA(count ~ pdq(,1,) + PDQ(,1,)), # default with D=d=1
# CO2 best glance(fit) |> arrange(AICc) |> select(.model:BIC)
      # arima_111_011 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,1)), 
      # CO2 opt long run & 1.best CO2 & 1.best Temperature & 2.best Precip
    arima_012_011 = ARIMA(count ~ pdq(0,1,2) + PDQ(0,1,1)), 
      # 2.best CO2 & 2.best Temperature & 1.best Precip
    arima_111_012 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,2)), 
    # 3.best CO2 & 3.best Temperature & 3.best Precip
# Temperature best glance(fit) |> arrange(AICc) |> select(.model:BIC)
      # arima_111_011 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,1)), 
      # CO2 opt long run & 1.best CO2 & Temperature
      # arima_012_011 = ARIMA(count ~ pdq(0,1,2) + PDQ(0,1,1)), 
      # 2.best CO2 & 2.best Temperature & 1.best Precip
        # arima_111_012 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,2)), 
        # 3.best CO2 &  3.best Temperature & 3.best Precip
# Precipitation best glance(fit) |> arrange(AICc) |> select(.model:BIC)     
##  1 arima_012_011  1229.  -3546. 7099. 7099. 7118.
##  2 arima_111_011  1229.  -3546. 7099. 7099. 7118.
##  3 arima_111_012  1230.  -3545. 7101. 7101. 7124
        # arima_002_200 = ARIMA(count ~ pdq(0,0,2) + PDQ(2,0,0)), 
        # arima_012_012 = ARIMA(count ~ pdq(0,1,2) + PDQ(0,1,2)), 
        arima_010_110 = ARIMA(count ~ pdq(0,1,0) + PDQ(1,1,0)),
        arima_210_110 = ARIMA(count ~ pdq(2,1,0) + PDQ(1,1,0)), 
        arima_211_011 = ARIMA(count ~ pdq(2,1,1) + PDQ(0,1,1)), # # best for CO2
        arima_111_010 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,0)),
        arima_110_010 = ARIMA(count ~ pdq(1,1,0) + PDQ(0,1,0)), # best Temp w/ d=D = 1
        arima_012_010 = ARIMA(count ~ pdq(0,1,2) + PDQ(0,1,0)),
        arima_100_210 = ARIMA(count ~ pdq(1,0,0) + PDQ(2,1,0)), 
        arima_100_110_c = ARIMA(count ~ 1 + pdq(2,0,0) + PDQ(1,1,0)),
        arima_200_011 = ARIMA(count ~ pdq(2,0,0) + PDQ(1,1,0)),  
        arima_200_110_c  = ARIMA(count ~ 1 + pdq(2,0,0) + PDQ(1,1,0)), # 2nd best for Temp
        )

cat("Model Selection by Information Criterion - lowest AIC, AICc, BIC\n", 
"choose p, q parameter accordingly - but only for same d, D values \n")
for(i in 1:measure_nr) {
  print(
    glance(fit_arima_all) %>% 
      arrange(AICc, AIC, BIC) %>%  
      select(City:BIC)  %>% 
      filter(Measure == measure[i]) %>% 
      slice(1:8)
  )
}

# provides a one-row summary of model-level statistics.
# glance(fit_arima_all) %>% summarise(min(AIC), min(AICc), min(BIC))
# report(fit_arima_all) # only working for single models !


# components(fit_arima_all) #  method not applicable for objects with class "ARIMA" 

```

Good models are obtained by minimising the AIC, AICc or BIC (see glance(fit_arima) output).
The preference is to use the AICc to selec $p$ and $q$.

These information criteria tend not to be good guides to selecting the
appropriate order of differencing $(d)$ of a model, but only for selecting the 
values of $p$ and $q$. This is because the differencing changes the data on which 
the likelihood is computed, making the AIC values between models with 
different orders of differencing not comparable. 

### Residual Accuracy with one-step-ahead fitted residuals - check RMSE, MAE

Residual accuracy can be computed directly from models as the one-step-ahead fitted residuals are available. Select forecast models that minimises for lowest

* MAE (Mean absolute error, will lead to forecasts of the median) and 
* RMSE (Root mean squared error, lead to forecasts of the mean)

```{r Residual accuracy ARIMA, eval = eval_arima}

# Residual accuracy
# can be computed directly from models as the one-step-ahead fitted residuals
# are available  
# check forecast method that minimises for lowest 
# MAE (Mean absolute error, will lead to forecasts of the median) and 
# RMSE (Root mean squared error, lead to forecasts of the mean)

for(i in 1:measure_nr) {
  print(
    fit_arima_all %>% 
      accuracy() %>% 
      arrange(RMSE, MAE) %>% 
      select(1:MAE) %>% 
      filter(Measure == measure[i]) %>% 
      slice(1:8)
  )
}

```

### Ljung-Box Test - independence/white noise of the forecasts residuals

```{r Model model ljung_box test residuals, eval = eval_arima}

# ljung_box Test: dof - Degrees of freedom of the fitted model 
#                           (useful if x is a series of residuals)
# dof = sum(p,q,P,Q) => should be 4 (not 6)
cat("Null Hypothesis of independence/white noise for residuals - for p < 0.05: reject H_0\n")

for(i in 1:measure_nr) {
  print(
    augment(fit_arima_all) %>%
      features(.resid, ljung_box, lag = 24, dof = 3) %>% 
      arrange(desc(lb_pvalue)) %>% 
      filter(Measure == measure[i]) %>% 
      slice(1:8)
  )
}


```



### Forecast Accuracy with Training/Test Data

```{r forecasts accuracy ARIMA, eval = eval_arima}
# forecasts accuracy with training data
# for evaluating accuracy on forecasts to be provided:
# - a complete dataset that includes the future data and 
# - data used to train the model

# forecast_test_data_range
# training_data_year_start 
# training_data_year_end 
# 
# training data 1970-2009, total data: 1970 - 2019, => test data: 2010-2019
# model fit period of time:
#           training_data_year_start - until last data = last_year (1970-2019)
fit_arima_train <- filter(data_monthly, 
                        year(Year_Month) > training_data_year_start  &
                          year(Year_Month) <= training_data_year_end) %>%
  model(
    # default = ARIMA(count, stepwise = FALSE, approx = FALSE),
        # arima_x1y_m1n = ARIMA(count ~ pdq(,1,) + PDQ(,1,)), # default with D=d=1
        # arima_002_200 = ARIMA(count ~ pdq(0,0,2) + PDQ(2,0,0)), # best for Precip
        # arima_012_012 = ARIMA(count ~ pdq(0,1,2) + PDQ(0,1,2)),
        arima_012_011 = ARIMA(count ~ pdq(0,1,2) + PDQ(0,1,1)),
        # arima_102_211 = ARIMA(count ~ pdq(1,0,2) + PDQ(2,1,1)), # Temperature opt short run
        arima_111_011 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,1)), # CO2 opt long run, best Temperature
        # arima_111_112 = ARIMA(count ~ pdq(1,1,1) + PDQ(1,1,2)), # CO2 opt short run
        # arima_111_012 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,2)),
        # arima_010_110 = ARIMA(count ~ pdq(0,1,0) + PDQ(1,1,0)),
        # arima_210_110 = ARIMA(count ~ pdq(2,1,0) + PDQ(1,1,0)), 
        arima_211_011 = ARIMA(count ~ pdq(2,1,1) + PDQ(0,1,1)), # # best for CO2
        # arima_111_010 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,0)),
        # arima_110_010 = ARIMA(count ~ pdq(1,1,0) + PDQ(0,1,0)), # best Temp w/ d=D = 1
        # arima_012_010 = ARIMA(count ~ pdq(0,1,2) + PDQ(0,1,0)),
        # arima_100_210 = ARIMA(count ~ pdq(1,0,0) + PDQ(2,1,0)), 
        # # arima_100_110 = ARIMA(count ~ 1 + pdq(2,0,0) + PDQ(1,1,0)),
        # arima_200_011 = ARIMA(count ~ pdq(2,0,0) + PDQ(1,1,0)),  
        # # arima_200_110 = ARIMA(count ~ 1 + pdq(2,0,0) + PDQ(1,1,0)), # 2nd best for Temp
        # arima_300_111 = ARIMA(count ~ pdq(3,0,0) + PDQ(1,1,0)), # Temperature opt long run
        # arima_301_200 = ARIMA(count ~ 1 + pdq(3,0,1) + PDQ(2,0,0))
        )
    

fc_arima_train <- fit_arima_train %>% fabletools::forecast(h = forecast_test_data_range) # long running
fc_arima_train_save <- fc_arima_train  # be careful to keep the long running calculations
# select best models according minimization of AICc and RMSE
# if (measure == "CO2") {
  fc_arima_train <- filter(fc_arima_train, 
                       .model == "arima_111_011" | 
                       .model == "arima_012_011" |
                       .model == "arima_211_011")
# } else if (measure == "Temperature") {
#   fc_arima_train <- filter(fc_arima_train, 
#                        .model == "arima_111_011" | 
#                        .model == "arima_012_011" |
#                        .model == "arima_211_011")
# } else if (measure == "Precipitation") {
#   fc_arima_train <- filter(fc_arima_train, 
#                        .model == "arima_012_011" | 
#                        .model == "arima_111_011" | 
#                        .model == "arima_111_012")
# }

accuracy(fc_arima_train, 
         filter(data_monthly, year(Year_Month) > training_data_year_start )) %>% 
  arrange(RMSE, MAE) %>% 
  select(1:MAE)


# with further data filtering only xlims are adapted, no forecast impact
# level = prediction interval in % or NULL
fc_arima_train %>%
  autoplot(filter(data_monthly, year(Year_Month) >= 2000), level = NULL) +
  labs(x = "Year", y = y_label) +
  ggtitle("Accuracy of Monthly Forecasts w/ Training and Test data", paste(city, "-", measure)) +
  guides(colour=guide_legend(title="Forecast"))

```



```{r ARIMA model forecast, eval = eval_arima}

# calculate forecasts
fc_arima_all <- fit_arima_all %>% fabletools::forecast(h = forecast_test_data_range) 
# long running

fc__arima_all_save <- fc_arima_all  # be careful to keep the long running calculations
fc_arima_all <- filter(fc_arima_all, .model == "arima_012_012" | 
                     #  .model == "arima_111_012" | # overlapping w/ _012_012
                       .model == "arima_301_200" |  # straigth mean line
                       .model == "arima_100_210")

# Plot ARIMA model forecasts and choose appropriate range of data before forecast
# data <- filter(data_monthly, year(Year_Month) >= 2010) 
# fc_arima_all %>%
#   autoplot(data, level = 95, alpha = 0.5) +
#   # autoplot: data + forecast AAA & forecast MAA w/ or w/o signif. level 
#   #           (prediction interval);  level = NULL rsp level = 95 (=95%))
#   labs( x = "Year", y = y_label,
#         title = "Forecasts by ARIMA models") +
#   guides(colour = guide_legend(title = "Forecast"))

```



```{r ARIMA selected model acc CO2 Temp Precip, eval = eval_arima}

#######################################################
## Mauna Loa best: all fine, more or less the same
# arima_111_012 = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,2)) => selected
# arima_111_112 = ARIMA(count ~ pdq(1,1,1) + PDQ(1,1,2))
# arima_012_012 = ARIMA(count ~ pdq(0,1,2) + PDQ(0,1,2))
# arima_211_011 = ARIMA(count ~ pdq(2,1,1) + PDQ(0,1,1))
#######################################################

# best models - selection based on
# ACF, PACF plots, AICc, residual accuracy, trainig accuracy

# if (measure == "CO2") {
#   # model_best <- expr("model(arima = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,1)))")
  fit_arima <- 
    filter(data_monthly, year(Year_Month) > training_data_year_start) %>% 
    model(arima = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,1)))
  selected_arima_model <- "arima_111_011"
# } else if (measure == "Temperature") {
#   fit_arima <- filter(data_monthly, year(Year_Month) > training_data_year_start) %>% 
#     model(arima = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,1)))
#   selected_arima_model <- "arima_111_011"
# } else if (measure == "Precipitation") {
#   fit_arima <- filter(data_monthly, year(Year_Month) > training_data_year_start) %>% 
#     model(arima = ARIMA(count ~ pdq(1,1,1) + PDQ(0,1,1)))
#   selected_arima_model <- "arima_111_011"
# }

model_arima <- as.character(format(fit_arima$arima))

```

\newpage

## `r measure` - Forecasting with selected ARIMA model `r model_arima` 

### Forecast Plot of selected ARIMA model

```{r Plot selected ARIMA model forecast, eval = eval_arima}

cat("Provide model coefficients by report(fit_model)")
report(fit_arima)
 
# fit_arima %>% gg_tsresiduals(lag_max= 36) + 
#   ggtitle("Model ", 
#           as.character(format(fit_arima$arima)))

# calculate forecasts
fc_arima <- fit_arima %>% fabletools::forecast(h = "30 years")

data <- filter(data_monthly, year(Year_Month) >= 2010)

# Plot ARIMA model forecasts and choose appropriate range of data before forecast
#  autoplot: data + forecast AAA & forecast MAA w/ or w/o signif. level (def=80&95%)
#   /prediction interval;  level = NULL /= 95 => w/o signif. level / w/ 95% 
fc_arima %>% 
    autoplot(data,  alpha = 0.5) +
    labs(x = "Year", y = y_label, col = "Forecast",
        title = paste("Forecasts by ARIMA model", model_arima),
        subtitle = "w/ Prediction Interval")

# augment(fit_arima) %>%
#   features(.resid, ljung_box, lag = 24, dof = 3)

```

### Residual Stationarity

Required checks to be ready for forecasting:

* ACF Forecast Residual: all spikes are within the significance limits, so the residuals appear to be white noise
* The Ljung-Box test also shows that the residuals have no remaining autocorrelations
* Forecast Residuals are more or less normally distributed with roughly centred on zero

```{r Plot ARIMA ACF Residuals, eval = eval_arima}

#     if AICc worsening !! => increasing prediction intervalls
# old AICc=7559.2 better W/ pdq(0,1,2) $PDQ((0,1,1)

# residuals(fit_arima)
# residuals(fit_arima, type = "response")

# a correlogram of the forecast errors 
# acf(rainseriesforecasts2$residuals, lag.max=20)
#  filter for single model not required
plot_1 <- filter(residuals(fit_arima), .model == "arima") %>%  
  ACF(.resid, lag.max = 36) %>% autoplot() +
  labs(title = "ACF Correlogram - Forecast Residuals",  subtitle = model_arima) +
    facet_wrap(vars(!!!key(data_monthly)), ncol = 1,  scales = "free_y",
             strip.position = "left")
plot_2 <- filter(residuals(fit_arima), .model == "arima") %>%
  PACF(.resid, lag.max = 36) %>% autoplot() +
  labs(title = "PACF - Forecast Residuals", subtitle = model_arima) +
    facet_wrap(vars(!!!key(data_monthly)), ncol = 1,  scales = "free_y",
             strip.position = "left")
gridExtra::grid.arrange(plot_1, plot_2)

```

```{r ARIMA forecast residuals, eval = eval_arima}
## !! for data with more than one time series
## => filter a single time series to use gg_lag(), gg_tsdisplay(), gg_tsresiduals

## arttention: for Cottbus Plot with Spectrum throws an error =>error = TRUE !!
## - up to know only for Cottbus Precipitation (w/ Temperature running) 
## - Fehler in .$spec[, 1] : falsche Anzahl von Dimensionen

year_filter <- 2000

if (n_keys(data_monthly) == 1 | length(key(data_monthly)) == 2) {    
  for (i in unique(key_data(data_monthly)[[1]])) {
    for (j in unique(key_data(data_monthly)[[2]])) {
      plot_ts <- fit_arima %>%  filter(City == i & Measure == j) %>%  
        gg_tsresiduals() + 
        labs( x = "Year", y = y_label_measure[j], 
              title = " Forecast Residuals w/ ACF Correlogram and Histogram", 
       subtitle = paste("Model:", model_arima))
      print(plot_ts)
      
    }
  } 
} else {
  abort(paste("nothing implemented for n_keys/key_data/key(data_monthly) =", 
              n_keys(data_monthly), key_data(data_monthly), (key(data_monthly))))
}
```

### Ljung-Box Test and Histogram of forecast residuals with overlaid normal curve


```{r Ljung-Box Test Arima, eval = eval_ets_arima}

cat("Null Hypothesis of independence/white noise for residuals - for p < 0.05: reject H_0\n")
augment(fit_arima) %>% filter(year(Year_Month) >= year_filter) %>% 
  features(.resid, ljung_box, lag = 24, dof = 3)

```


```{r Ljung-Box Tests residuals ARIMA, eval = eval_arima, fig.width= 7, fig.height= 4}

# check for independence/white noise of residuals => ljung_box test

# check whether the forecast errors are normally distributed with mean zero
# => plot histogram of forecast errors, with an overlaid normal curve with 
#    same mean zero and standard deviation

# plot residual histogram with overlaid normal curve 
#  => overlaid normal curve not working correct with facet_wrap()

# if (n_keys(data) == 2 | length(key(data)) == 3) { # one key added by .model
for (i in unique(key_data(data)[[1]])) {     # City
  for (j in unique(key_data(data)[[2]])) {   # Measure
    
    data_filtered <- filter(augment(fit_arima), year(Year_Month) >= year_filter & 
                              City == i, Measure == j)
    plot_histo <- ggts_histo_forecast_resid(data_filtered) +
      labs(title = paste("Histogram of Forecast Residuals -", i, j),  
           subtitle = model_arima)
    print(plot_histo)
  }
}
# } else {
#   abort(paste("nothing implemented for n_keys/key_data/key(data_monthly) =", 
#               n_keys(data_monthly), key_data(data_monthly), (key(data_monthly))))
# }

```


\newpage

# ARIMA vs ETS

In particular, all ETS models are non-stationary, while some ARIMA models are stationary.

The ETS models with seasonality or non-damped trend or both have two unit roots 
(i.e., they need two levels of differencing to make them stationary). All other ETS models have one unit root (they need one level of differencing to make them stationary).

We compare for the chosen ETS rsp. ARIMA model the RMSE / MAE values. Lower 
values indicate a more accurate model based on the test set RMSE, ..., MASE.

* Residual Accuracy with one-step-ahead fitted residuals
* Forecast Accuracy with Training/Test Data

Note: a good fit to training data is never an indication that the model will 
forecast well. Therefore the values of the Forecast Accuracy are the more relevant one.

### Comparing Residual and Forecast Accuracy of selected ETS and ARIMA model

```{r compare residual and forecast accuracy faulty, eval = eval_ets_arima}
## Comparing ARIMA() and ETS() on seasonal data

bind_rows(
  fit_ets %>% accuracy(),
  fit_arima %>% accuracy(),
  accuracy(filter(fc_ets_train, .model == selected_ets_model), 
           filter(data_monthly, year(Year_Month) > training_data_year_start)),
  accuracy(filter(fc_arima_train, .model ==  selected_arima_model),
           filter(data_monthly, year(Year_Month) > training_data_year_start))
  ) %>% 
   select(-ME, -MPE, -ACF1) %>% 
  arrange(Measure, RMSE)

```

### Forecast Plot of selected ETS and ARIMA model

```{r ETS Time Series Residuals Histo Forecast, eval = eval_ets_arima}

# if (measure == "CO2") {
#   # model_best <- expr("model(arima = ARIMA(count~ pdq(1,1,1) + PDQ(0,1,2)))")
  fit_ets_arima <- filter(data_monthly, year(Year_Month) > training_data_year_start) %>% 
    model(ETS_AAA = ETS(count~ error("A") + trend("A") + season("A")),
          arima_111_011 = ARIMA(count~ pdq(1,1,1) + PDQ(0,1,1)))
# } else if (measure == "Temperature") {
#   fit_ets_arima <- filter(data_monthly, year(Year_Month) > training_data_year_start) %>% 
#       model(ets = ETS(count~ error("A") + trend("A") + season("A")),
#             arima = ARIMA(count~ pdq(0,1,2) + PDQ(0,1,2)))
# } else if (measure == "Precipitation") {
#   fit_ets_arima <- filter(data_monthly, year(Year_Month) > training_data_year_start) %>% 
#     model(ets = ETS(count~ error("A") + trend("A") + season("A")),
#           arima = ARIMA(count~ pdq(0,1,2) + PDQ(0,1,2)))
#}

fc_ets_arima_monthly <- fit_ets_arima %>% fabletools::forecast(h = "25 years")

# Plot ARIMA model forecasts and choose appropriate range of data before forecast
#  autoplot: data + forecast AAA & forecast MAA w/ or w/o signif. level (def=80&95%)
#   /prediction interval;  level = NULL /= 95 => w/o signif. level / w/ 95% 
data <- filter(data_monthly, Year >= 2010) 
fc_ets_arima_monthly %>% 
    autoplot(data) +
    labs(x = "Year", y = y_label, col = "Forecast",
        title = paste("Forecasts by ETS ", model_ets," and ARIMA model", model_arima),
        subtitle = "w/ Prediction Interval") 

```

```{r test for yearly(mean), eval = eval_ets_arima}

# hilo() provides confidence intervals
# slice(hilo(fc_ets_arima_monthly) %>% group_by(City, Measure, .model), 1:3)  
# slice(hilo(fc_ets_arima_monthly) %>% group_by(City, Measure, .model), n() -2:0) 

data <- filter(data_monthly, Year >= 1900) 
fc_ets_arima_monthly %>% 
    autoplot(data) +
    labs(x = "Year", y = y_label, col = "Forecast",
        title = paste("Forecasts by ETS ", model_ets," and ARIMA model", model_arima),
        subtitle = "w/ Prediction Interval") 

yearly_ets_arima_forecasts <- fc_ets_arima_monthly %>%
    index_by(Year = ~ year(.)) %>%
    as_tibble() %>% 
    group_by(City, Measure, .model, Year) %>% 
    summarise(count = mean(count))
# slice(yearly_ets_arima_forecasts, 1:3)  # mean Jan, Feb, March
# slice(yearly_ets_arima_forecasts, n() -2:0) # mean Oct, Nov, Dec

# qnorm(0.975, mean =0, sd = 1.75558599)  # sd got from monthly data signif. level
# qnorm(0.975, mean =13, sd = 0.547)    # sd got via yearly_avg


# data_temp_fc <- yearly_ets_arima_forecasts %>%
#   group_by(.model, City, Measure, Year) %>%  
#   summarise(Mean = mean(count))


```
\newpage



```{r mean data table of past time periods, eval = TRUE}

data_monthly <- data_monthly %>% 
  mutate(Period_Time =  
           paste0((((Year-11) %/% 30) * (30)) + 11, "-", (((Year-11) %/% 30) * (30)) + 40)) %>% 
  mutate(Period_Time = 
           case_when(Period_Time == "2021-2050" ~ paste0("2021-", last_year),
                     .default = Period_Time
                     ))

data_yearly <- data_yearly %>% 
  mutate(Period_Time =  
           paste0((((Year-11) %/% 30) * (30)) + 11, "-", (((Year-11) %/% 30) * (30)) + 40)) %>% 
  mutate(Period_Time = 
           case_when(Period_Time == "2021-2050" ~ paste0("2021-", last_year),
                     .default = Period_Time
                     ))

data_yearly_period <- tibble(data_yearly) %>% group_by(City, Measure, Period_Time) %>% 
  summarise(Mean = mean(count))
data_yearly_monthly <- tibble(data_monthly) %>% group_by(City, Measure, Year, Period_Time) %>% 
  summarise(Mean = mean(count)) 
data_yearly_monthly_period <- data_yearly_monthly %>% group_by(City, Measure, Period_Time) %>% 
  summarise(Period_Mean = mean(Mean)) 

data_yearly_monthly_period_wide <- data_yearly_monthly_period %>% 
  ungroup() %>% select(-City) %>% 
  pivot_wider(names_from = Measure,
              values_from = Period_Mean)

knitr::kable(data_yearly_monthly_period_wide, digits = 1, 
             caption = "Mean values for the given time periods; 
Units: Temperature (degree C), Precipitation (mm/Month), CO2 (ppm)")

```

```{r ETS ARIMA Forecast Table yearly mean of monthly data, eval = eval_ets_arima}

cond <- c(last_year + 1, seq.int(2030, 2050, 5))
Year.x = last_year + 1 
Year.y = 2050

fc_monthly_ets_arima <- fit_ets_arima %>% fabletools::forecast(h = "25 years")
fc <- fc_monthly_ets_arima %>% 
  mutate(Year =  year(Year_Month)) %>% 
  group_by(City, Measure, .model, Year)

data_monthly_fc <- tibble(fc) %>% 
  group_by(City, Measure, .model, Year)

data_yearly_fc <- tibble(fc) %>% 
  group_by(City, Measure, .model, Year) %>% 
  summarise(Yearly_Mean = mean(.mean))

data_yearly_fc_wide <- data_yearly_fc %>% 
  pivot_wider(names_from = .model,
              values_from = Yearly_Mean)

data_filter_fc <- filter(data_yearly_fc_wide,
                         Year == cond[1] | Year == cond[2] | 
                         Year == cond[3] | Year == cond[4] | 
                         Year == cond[5] | Year == cond[6])

knitr::kable(data_filter_fc, digits = 2, 
             caption = "Mean Yearly ARIMA and ETS Forecast values (next 25 years);
Units: Temperature (degree C), Precipitation (mm/Month), CO2 (ppm)")


```


```{r ETS ARIMA Yearly Forecast of monthly data Table delta}

x <- data_yearly_fc %>% filter(Year == Year.x) %>% rename(Mean = Yearly_Mean)
y <- data_yearly_fc %>% filter(Year == Year.y) %>% rename(Mean = Yearly_Mean)

z <- left_join(x, y, join_by(City, Measure, .model)) %>% 
  mutate(Delta = Mean.y - Mean.x)

z_wide <- z %>% 
  pivot_wider(names_from = .model,
              values_from = c(Mean.x, Mean.y, Delta)) %>% 
  rename(ETS.x = Mean.x_ETS_AAA, 
         ARIMA.x = Mean.x_arima_111_011,
         ETS.y = Mean.y_ETS_AAA, 
         ARIMA.y = Mean.y_arima_111_011,
         Delta_ETS = Delta_ETS_AAA, 
         Delta_ARIMA = Delta_arima_111_011)

data_z_wide <- z_wide %>% ungroup() %>% 
  select(-City, Measure,  
         Year.x, Year.y, 
         ETS.x, ARIMA.x, ETS.y, ARIMA.y, Delta_ETS, Delta_ARIMA)

knitr::kable(data_z_wide, digits = 2, 
             caption = "Forecast increase/decrease over the next 25 years;
Units: Temperature (degree C), Precipitation (mm/Month), CO2 (ppm)")

```

```{r test for yearly(mean) table A, eval = FALSE}

# x_jan <- paste(last_year + 1, "Jan")
# x_dec <- paste(last_year + 1, "Dec")
# y_jan <- paste(last_year + 25, "Jan")
# y_dec <- paste(last_year + 25, "Dec")
# 
# x <- as_tibble(fc_ets_arima_monthly %>% filter_index(x_jan ~ x_dec)) %>% 
#   mutate(month = month(Year_Month, label = TRUE, locale = "UTC")) %>% 
#   rename(Mean = .mean)
# y <- as_tibble(fc_ets_arima_monthly %>% filter_index(y_jan ~ y_dec)) %>% 
#   mutate(month = month(Year_Month, label = TRUE, locale = "UTC")) %>% 
#   rename(Mean = .mean)
# 
# z <- left_join(x, y, join_by(City, Measure, .model, month)) %>% 
#   mutate(Diff = Mean.y - Mean.x)
# 
# data_z <- z %>% 
#   select(City, Measure, .model, 
#          Year_Month.x, Year_Month.y, 
#          Mean.x, Mean.y, Diff)
# 
# knitr::kable(data_z, digits = 2, caption =
#                "Forecast increase/decrease over the next 25 years (monthly slices)")

```

```{r ETS ARIMA Monthly Forecast Table delta, eval = TRUE}
# for ETS model in principle no monthly delta difference
# for ARIMA model very small differences only => Yearly Forecast Table delta suficient 

x_m <- data_monthly_fc %>% filter(Year == Year.x) %>% ungroup() %>% 
  rename(Mean.x = .mean, Year_Month.x = Year_Month) %>% select(-count, -Year) %>% 
 separate(Year_Month.x, c("Year.x", "Month"))
y_m <- data_monthly_fc %>% filter(Year == Year.y) %>% ungroup() %>% 
  rename(Mean.y = .mean, Year_Month.y = Year_Month) %>% select(-count, -Year) %>% 
  separate(Year_Month.y, c("Year.y", "Month"))

z_m <- left_join(x_m, y_m, join_by(City, Measure, .model, Month)) %>%
  mutate(Delta = Mean.y - Mean.x)

z_m_wide <- z_m %>% 
  pivot_wider(names_from = .model,
              values_from = c(Mean.x, Mean.y, Delta)) %>% 
  rename(ETS.x = Mean.x_ETS_AAA, 
         ARIMA.x = Mean.x_arima_111_011,
         ETS.y = Mean.y_ETS_AAA, 
         ARIMA.y = Mean.y_arima_111_011,
         Delta_ETS = Delta_ETS_AAA, 
         Delta_ARIMA = Delta_arima_111_011)


data_z_m_wide <- z_m_wide %>% 
  select(Measure,   
         Month, Year.x, Year.y, 
         ETS.x, ARIMA.x, ETS.y, ARIMA.y, Delta_ETS, Delta_ARIMA)

knitr::kable(data_z_m_wide, digits = 2, 
             caption = "Forecast increase/decrease over the next 25 years;
Units: Temperature (degree C), Precipitation (mm/Month), CO2 (ppm)")


```




\newpage

# Yearly Data Forecasts with ARIMA and ETS 

For yearly data the seasonal monthly data are replaced by the yearly average 
data. Therefore the seasonal component of the ETS and ARIMA model are to be taken
out.

The ETS model $<ETS(A,A,N)>$  with seasonal term change "A" -> "N" is chosen. 
For ARIMA models the seasonal term (P,D,Q)m has to be taken out and an optimal
ARIMA(p,1,q) with one differencing (d=1) is selected. However, for Mauna Loa two
times differncing had to be selected $CO_2 <ARIMA(0,2,1) w/ poly>.
For Temperature and Precipitation the same model as for monthly data can be 
taken by leaving out the seasonal term $<ARIMA(0,1,2) w/ drift>$.

### Comparing Residual and Forecast Accuracy of selected ETS and ARIMA model

### Forecast Plot of selected ETS and ARIMA model

```{r Yearly ETS ARIMA Forecast of mean yearly data, eval = eval_yearly}

# if (measure == "CO2") {
#   # model_best <- expr("model(arima = ARIMA(count~ pdq(1,1,1) + PDQ(0,1,2)))")
  fit_year_ets_arima <- filter(data_yearly, Year > training_data_year_start) %>% 
      model(ets_def = ETS(count),
            ETS_AAN = ETS(count ~ error("A") + trend("A") + season("N")),
            arima_def = ARIMA(count),
            arima_111wd = ARIMA(count ~ 1 + pdq(1,1,1)))
# } else if (measure == "Temperature") {
#   fit_year_ets_arima <- filter(data_yearly, Year > training_data_year_start) %>% 
#       model(ets = ETS(count ~ error("A") + trend("A") + season("N")),
#             arima_count= (count), 
#           # arima = ARIMA(count ~ 1 + pdq(0,1,2)))
#             arima = ARIMA(count ~ 1 + pdq(1,1,1)))
# } else if (measure == "Precipitation") {
#   fit_year_ets_arima <- filter(data_yearly, Year > training_data_year_start) %>% 
#     model(ets = ETS(count ~ error("A") + trend("A") + season("N")),
#             arima = ARIMA(count ~ 1 + pdq(1,1,1)))
# }


model_year_ets <- as.character(format(fit_year_ets_arima$ETS_AAN))
model_year_arima <- as.character(format(fit_year_ets_arima$arima_111wd))

cat("selected: ETS_AAN and arima_111 w/ drift")
fit_year_ets_arima <- fit_year_ets_arima %>% select(-ets_def, -arima_def)
fc_year_ets_arima <- fit_year_ets_arima %>% fabletools::forecast(h = "25 years")

# Plot ARIMA model forecasts and choose appropriate range of data before forecast
#  autoplot: data + forecast AAA & forecast MAA w/ or w/o signif. level (def=80&95%)
#   /prediction interval;  level = NULL /= 95 => w/o signif. level / w/ 95%

data <- filter(data_yearly, Year >= first_year) 
fc_year_ets_arima %>% 
    autoplot(data) +
    labs(x = "Year", y = y_label, col = "Forecast",
        title = paste("Yearly Forecasts by ETS ", 
                      model_year_ets," and ARIMA model", model_year_arima),
        subtitle = "w/ Prediction Interval") 

data <- filter(data_yearly, Year >= (last_year - 30)) 
fc_year_ets_arima %>% 
    autoplot(data) +
    labs(x = "Year", y = y_label, col = "Forecast",
        title = paste("Yearly Forecasts by ETS ", 
                      model_year_ets," and ARIMA model", model_year_arima),
        subtitle = "w/ Prediction Interval") 

glance( fit_year_ets_arima) %>% arrange(AICc)


```
Ljung-Box Test - independence/white noise of the forecasts residuals

```{r Yearly Ljung-Box Test ETS Arima, eval = eval_yearly}

# We suggest using L=10 for non-seasonal data and  L=2m for seasonal data, 
# where  m is the period of seasonality. 
# lag = 2*m (period of season, e.g. m=12 for monthly season) | no season: lag=10
#     + dof = p + q + P + Q (for ARIMA models only, degree of freedom)

augment(fit_year_ets_arima %>% select(ETS_AAN)) %>%
  features(.resid, ljung_box, lag = 24)

augment(fit_year_ets_arima %>% select(arima_111wd)) %>%
  features(.resid, ljung_box, lag = 24, dof = 3)

```

\newpage


```{r Long run Yearly ETS ARIMA Forecast of mean yearly data, eval = eval_yearly}

# hilo() provides confidence intervals
# slice(hilo(fc_year_ets_arima) %>% group_by(City, Measure, .model), 1:3)  
# slice(hilo(fc_year_ets_arima) %>% group_by(City, Measure, .model), n() -2:0) 
# data_temp_fc <- slice(hilo(fc_year_ets_arima) %>% group_by(City, Measure, .model), n() -25:0)
# data_temp_fc <- data_temp_fc %>% select(City, Measure, Year, .mean) %>% 
#   rename(Mean = .mean)



```

```{r Long run Yearly ETS ARIMA Forecast Table of mean yearly data, eval = eval_yearly}

# cond <- c(last_year + 1, seq.int(2030, 2050, 5))
# Year.x = last_year + 1 
# Year.y = 2050

# above:
# fc_year_ets_arima <- fit_year_ets_arima %>% fabletools::forecast(h = "25 years")

fc_y <- fc_year_ets_arima  %>% 
  group_by(City, Measure, .model)

data_yearly_fc_y <- tibble(fc_y) %>% 
  group_by(City, Measure, .model, Year) %>% 
  summarise(Yearly_Mean = mean(.mean))

data_yearly_fc_y_wide <- data_yearly_fc_y %>% 
  pivot_wider(names_from = .model,
              values_from = Yearly_Mean)
# data_yearly_fc_wide %>% rename(ETS_AAN = ets, arima_111 = arima)
# should be ETS_AAN & arima_pdq only w/o PDQ


data_filter_fc_y <- filter(data_yearly_fc_y_wide,
                         Year == cond[1] | Year == cond[2] | 
                         Year == cond[3] | Year == cond[4] | 
                         Year == cond[5] | Year == cond[6])

knitr::kable(data_filter_fc_y, digits = 2, 
             caption = "Mean Yearly ARIMA and ETS Forecast values of mean yearly data (next 25 years);
Units: Temperature (degree C), Precipitation (mm/Month), CO2 (ppm)")

```


```{r ETS ARIMA Yearly Forecast of yearly mean data Table delta, eval = TRUE}

xy <- data_yearly_fc_y %>% filter(Year == Year.x) %>% rename(Mean = Yearly_Mean)
yy <- data_yearly_fc_y %>% filter(Year == Year.y) %>% rename(Mean = Yearly_Mean)

zy <- left_join(xy, yy, join_by(City, Measure, .model)) %>% 
  mutate(Delta = Mean.y - Mean.x)

zy_wide <- zy %>% 
  pivot_wider(names_from = .model,
              values_from = c(Mean.x, Mean.y, Delta)) %>% 
  rename(ETS.x = Mean.x_ETS_AAN, 
         ARIMA.x = Mean.x_arima_111wd,
         ETS.y = Mean.y_ETS_AAN, 
         ARIMA.y = Mean.y_arima_111wd,
         Delta_ETS = Delta_ETS_AAN, 
         Delta_ARIMA = Delta_arima_111wd)

data_zy_wide <- zy_wide %>% ungroup() %>% 
  select(-City, Measure,  
         Year.x, Year.y, 
         ETS.x, ARIMA.x, ETS.y, ARIMA.y, Delta_ETS, Delta_ARIMA)

knitr::kable(data_zy_wide, digits = 2, 
             caption = "Forecast increase/decrease over the next 25 years;
Units: Temperature (degree C), Precipitation (mm/Month), CO2 (ppm)")

```

<!-- # Backup -->


```{r eval = eval_test}

## Stationary Process Test
#
# Strict-sense stationarity / Weak (wide-sense) stationarity
# 
# Trend Stationary - underlying trend (function solely of time) can be removed, 
# leaving a stationary process

## Stationarity Test
library(aTSA)     # for stationary.test(data_ts) and adf.test(data_ts) - same
## however, => name isse with fabletools::forecast
# library(fractal)  # for stationaryty()
#       Package 'fractal' is removed from the CRAN repository.
library(LaplacesDemon)

# data <- data_monthly_stlplus  # w/ numeric "Time"
# as.numeric(as.Date("2018-09-24") - as.Date("2017-10-24"))
# update data_ts with replaced NAs, e.g. adf.test() does not allow NAs
data_ts <- ts(data_monthly$count, start=c(first_year, 1), frequency = freq)

stationary.test(data_ts)
adf.test(data_ts)

# statio <-
#   stationarity(data_monthly$count, n.taper = 6,
#                n.block = max(c(12, floor(logb(length(data_ts), base = 12)))),
#                significance = 0.05, center = TRUE, recenter = FALSE)
# summary(statio)

is.stationary(data_monthly$count)
# statcheck() from Schlittgen
# source("./Data_Schlittgen/tsutil.R")
# statcheck(data_monthly$count, 5) #Berechnung der deskriptiven Maßzahlen ist elementar. 
     # Um die Kovarianzstationarität zu überprüfen, wird die Funktion eingesetzt
     #  plot ACF over Lag  for 5 segments
#  function statcheck determines the means, standard deviations and acf’s
#  of segments of a time series and plots the acf’s for the segments.

# vartable(data_ts,12) # variate Differenzen weisen darauf hin, dass einmal 
                     # einfache und einmal saisonale Differenzen zu bilden sind
                     # sind, um Stationarität zu erreichen.



# bandfilt(data_ts, 7, 12, 24)
# View(data_ts)
# 
# (model_lm_1 <- lm(count ~ Year_Month, data))
# summary(model_lm_1)
# plot(model_lm_1)
# 
# model_lm_2 <- lm(count ~ Year_Month + Year_Month^2, data)
# summary(model_lm_2)
# plot(model_lm_2)


```


```{r Beispiel 10.10, eval = eval_test}
library(dlm)                                                                                 
# co2 <- scan("./Data_Schlittgen/schauinsland.dat")  
co2 <- data_ts  # co2 <- ts(co2,start = 2005,frequency=freq)
dlmco <- dlmModPoly(2) + dlmModSeas(12)
m1 <- c(382,0.1,rep(0,11))  
c1 <- diag(c( 0.1, 0.1, rep(100,11)))

buildFun <- function(x) { 
  W(dlmco)[1:3,1:3] <- diag(exp(x[1:3]))
  V(dlmco) <- exp(x[4]) 
  C0(dlmco) <- c1
  m0(dlmco) <- m1 
  return(dlmco)
}              

# Parameter estimation by maximum likelihood - very long runnning !!
fit <- dlmMLE(co2, parm=rep(1,4), build=buildFun)
fit$conv
dlm.co2 <- buildFun(fit$par)                                              
coFilter <- dlmFilter(co2, mod=dlm.co2)
coSmooth <- dlmSmooth(coFilter) 

plot(co2,type="o") 
lines(dropFirst(coFilter$m[,1]))
lines(dropFirst(coSmooth$s[,1]))
plot(dropFirst(coSmooth$s[,3]))

fut1 <- dlmForecast(coFilter, n=12)
x <- cbind(co2,fut1$f,fut1$f-1.96*sqrt(unlist(fut1$Q)),
           fut1$f+1.96*sqrt(unlist(fut1$Q)))                                
plot.ts(x,plot.type="s",lty=c(1,1,2,2)) 
points(2005+28/12,co2[29])

```


```{r end, echo = FALSE}
###########################################################################
Prog.End <- Sys.time()
run.time <- round((Prog.End - Prog.Start), digits = 2)
message("Program executed on: ", Prog.End, "\t Program run time: ", run.time, " secs")
```
